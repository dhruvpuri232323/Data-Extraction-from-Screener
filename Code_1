import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
from urllib.parse import urljoin, urlparse
import time
import json

class ScreenerScraper:
    def __init__(self):
        self.base_url = "https://www.screener.in"
        self.session = requests.Session()
        self.logged_in = False
        
        # Enhanced headers to mimic a real browser
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0'
        }
        
        self.session.headers.update(self.headers)
    
    def convert_to_number(self, value, debug=False):
        """
        Enhanced function to convert string values to appropriate numeric types
        Handles Indian numbering format, percentages, negatives, and currency
        Only keeps text for obvious company names and category fields
        """
        if pd.isna(value) or value is None or value == '':
            return None
        
        # Convert to string if not already
        original_value = str(value).strip()
        
        # Return as-is if it's already a number
        if isinstance(value, (int, float)):
            return value
        
        # Define patterns that should definitely stay as text (company names and categories)
        text_only_indicators = [
            'ltd', 'limited', 'inc', 'corp', 'pvt', 'private', 'public',
            'company', 'industries', 'group', 'holdings', 'ventures',
            'technologies', 'services', 'solutions', 'systems', 'india',
            'international', 'global', 'trading', 'exports', 'imports',
            'enterprises', 'corporation', 'manufacturing', 'textile',
            'pharmaceuticals', 'chemicals', 'steel', 'power', 'energy',
            'communications', 'infrastructure', 'engineering', 'finance'
        ]
        
        lower_value = original_value.lower()
        
        # Only keep as text if it's clearly a company name (has common suffixes AND is long)
        is_company_name = (
            len(original_value) > 15 and  # Must be reasonably long
            any(indicator in lower_value for indicator in text_only_indicators) and
            not any(char in original_value for char in ['%', 'â‚¹', 'Rs', 'cr', 'Cr', 'L', 'lakh'])  # No numeric indicators
        )
        
        if is_company_name:
            return original_value
        
        # Clean the string for numeric conversion
        cleaned_value = original_value
        
        # Handle special cases first
        if cleaned_value.lower() in ['n/a', 'na', 'nil', 'null', '-', '--', '']:
            return 0.0  # Convert null values to 0 for numeric consistency
        
        # Remove currency symbols and common prefixes
        cleaned_value = re.sub(r'^Rs\.?\s*', '', cleaned_value)
        cleaned_value = re.sub(r'â‚¹\s*', '', cleaned_value)
        cleaned_value = re.sub(r'^\$\s*', '', cleaned_value)
        
        # Handle percentage
        is_percentage = '%' in cleaned_value
        cleaned_value = cleaned_value.replace('%', '')
        
        # Handle negative numbers (keep track of sign)
        is_negative = False
        if cleaned_value.startswith('(') and cleaned_value.endswith(')'):
            is_negative = True
            cleaned_value = cleaned_value[1:-1]
        elif cleaned_value.startswith('-'):
            is_negative = True
            cleaned_value = cleaned_value[1:]
        
        # Remove commas and spaces
        cleaned_value = cleaned_value.replace(',', '').replace(' ', '')
        
        # Handle Indian numbering suffixes (Cr, L, K, etc.)
        multiplier = 1
        suffix_multipliers = {
            'cr': 10000000,      # 1 Crore = 10 Million
            'crore': 10000000,
            'crores': 10000000,
            'l': 100000,         # 1 Lakh = 100 Thousand
            'lakh': 100000,
            'lakhs': 100000,
            'k': 1000,          # 1 Thousand
            'thousand': 1000,
            'm': 1000000,       # 1 Million
            'million': 1000000,
            'b': 1000000000,    # 1 Billion
            'billion': 1000000000
        }
        
        # Check for suffix (case insensitive)
        for suffix, mult in suffix_multipliers.items():
            if cleaned_value.lower().endswith(suffix):
                multiplier = mult
                cleaned_value = cleaned_value[:-len(suffix)]
                break
        
        # Remove any remaining non-numeric characters except decimal point
        cleaned_value = re.sub(r'[^\d.]', '', cleaned_value)
        
        if not cleaned_value or cleaned_value == '.':
            return 0.0  # Convert empty values to 0
        
        try:
            # Convert to float
            numeric_value = float(cleaned_value) * multiplier
            
            # Apply negative sign if needed
            if is_negative:
                numeric_value = -numeric_value
            
            # Handle percentage (keep as percentage, don't convert to decimal)
            # This maintains the original percentage format for better readability
            
            # Convert to int if it's a whole number and not a percentage and not too large
            if not is_percentage and numeric_value.is_integer() and abs(numeric_value) < 1e15:
                numeric_value = int(numeric_value)
            
            if debug:
                print(f"Converted '{original_value}' -> {numeric_value} ({'%' if is_percentage else 'number'})")
            
            return numeric_value
            
        except (ValueError, TypeError):
            # If conversion fails, try one more time with more aggressive cleaning
            try:
                # Extract just numbers and decimal points
                numbers_only = re.findall(r'\d+\.?\d*', original_value)
                if numbers_only:
                    base_value = float(numbers_only[0])
                    
                    # Apply multipliers based on text content
                    if any(term in original_value.lower() for term in ['cr', 'crore']):
                        base_value *= 10000000
                    elif any(term in original_value.lower() for term in ['l', 'lakh']):
                        base_value *= 100000
                    elif 'k' in original_value.lower():
                        base_value *= 1000
                    
                    # Handle negatives
                    if '(' in original_value and ')' in original_value or original_value.startswith('-'):
                        base_value = -base_value
                    
                    if debug:
                        print(f"Fallback conversion '{original_value}' -> {base_value}")
                    
                    return int(base_value) if base_value.is_integer() else base_value
                
            except:
                pass
            
            # Final fallback: if it looks like it should be a number but conversion failed
            if any(char in original_value for char in '0123456789'):
                if debug:
                    print(f"Could not convert '{original_value}' to number, setting to 0")
                return 0.0
            
            # Keep as text only if it's clearly text
            if debug:
                print(f"Keeping '{original_value}' as text")
            return original_value
    
    def login(self, email="Dhruvpuri1346@gmail.com", password="Naveen41118"):
        """
        Login to Screener.in with the provided credentials
        """
        print("\nðŸ” Starting login process...")
        
        try:
            # First, get the login page to extract any required tokens/forms
            login_url = f"{self.base_url}/login/"
            print(f"   Fetching login page: {login_url}")
            
            response = self.session.get(login_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Look for login form
            login_form = soup.find('form')
            if not login_form:
                print("   âŒ Could not find login form")
                return False
            
            # Extract CSRF token if present
            csrf_token = None
            csrf_input = soup.find('input', {'name': 'csrfmiddlewaretoken'})
            if csrf_input:
                csrf_token = csrf_input.get('value')
                print(f"   Found CSRF token: {csrf_token[:20]}...")
            
            # Prepare login data
            login_data = {
                'username': email,
                'password': password,
            }
            
            if csrf_token:
                login_data['csrfmiddlewaretoken'] = csrf_token
            
            # Extract form action URL
            form_action = login_form.get('action', '/login/')
            if not form_action.startswith('http'):
                form_action = urljoin(self.base_url, form_action)
            
            print(f"   Submitting login to: {form_action}")
            
            # Add referer header for login
            login_headers = self.headers.copy()
            login_headers['Referer'] = login_url
            login_headers['Origin'] = self.base_url
            
            # Submit login
            login_response = self.session.post(
                form_action,
                data=login_data,
                headers=login_headers,
                timeout=30,
                allow_redirects=True
            )
            
            print(f"   Login response status: {login_response.status_code}")
            print(f"   Final URL after login: {login_response.url}")
            
            # Check if login was successful
            # Method 1: Check if we're redirected to dashboard or market page
            if 'login' not in login_response.url.lower():
                print("   âœ… Login successful (redirected away from login page)")
                self.logged_in = True
                return True
            
            # Method 2: Check the response content for success indicators
            login_soup = BeautifulSoup(login_response.content, 'html.parser')
            
            # Look for error messages
            error_messages = login_soup.find_all(['div', 'span', 'p'], class_=re.compile(r'error|alert|warning', re.I))
            if error_messages:
                error_text = ' '.join([msg.get_text(strip=True) for msg in error_messages])
                print(f"   âš ï¸ Possible error messages: {error_text}")
            
            # Look for success indicators (user menu, logout link, etc.)
            success_indicators = [
                login_soup.find('a', href='/logout/'),
                login_soup.find('a', text=re.compile(r'logout|sign out', re.I)),
                login_soup.find_all('a', href=re.compile(r'/screens/|/market/')),
            ]
            
            if any(success_indicators):
                print("   âœ… Login successful (found user session indicators)")
                self.logged_in = True
                return True
            
            # Method 3: Try to access a protected page
            test_url = f"{self.base_url}/market/"
            test_response = self.session.get(test_url, timeout=30)
            
            if test_response.status_code == 200:
                test_soup = BeautifulSoup(test_response.content, 'html.parser')
                
                # Look for "Edit Columns" button or similar authenticated features
                edit_columns = test_soup.find('button', text=re.compile(r'edit.*column', re.I))
                if edit_columns:
                    print("   âœ… Login successful (can access authenticated features)")
                    self.logged_in = True
                    return True
            
            print("   âŒ Login may have failed - proceeding anyway")
            return False
            
        except Exception as e:
            print(f"   âŒ Login error: {str(e)}")
            return False
    
    def extract_breadcrumb_hierarchy(self, soup, debug=False):
        """
        Enhanced breadcrumb extraction with login-aware features
        """
        hierarchy = {
            'Industry': 'Industries',
            'Driving_Category': '',
            'Category': '',
            'Sector': '',
            'Sub_Category': ''
        }
        
        if debug:
            print("\nðŸ” DEBUG: Starting breadcrumb extraction...")
        
        try:
            # Method 1: Look for breadcrumb navigation containers with various selectors
            breadcrumb_selectors = [
                'nav[aria-label*="breadcrumb"]',
                '.breadcrumb',
                'ol.breadcrumb',
                'ul.breadcrumb',
                'div.breadcrumb',
                '.nav-breadcrumb',
                '.breadcrumbs',
                'nav',
                '.navigation-path',
                '.path-navigation'
            ]
            
            breadcrumb_container = None
            
            for selector in breadcrumb_selectors:
                containers = soup.select(selector)
                for container in containers:
                    container_text = container.get_text().lower()
                    if 'industries' in container_text:
                        breadcrumb_container = container
                        if debug:
                            print(f"Found breadcrumb container using selector: {selector}")
                        break
                if breadcrumb_container:
                    break
            
            # Method 2: Look for page title or heading that might contain hierarchy
            if not breadcrumb_container:
                title_elements = soup.find_all(['h1', 'h2', 'h3', '.page-title', '.section-title'])
                for title in title_elements:
                    title_text = title.get_text(strip=True)
                    if len(title_text) > 5 and any(word in title_text.lower() for word in ['companies', 'industry', 'sector']):
                        # This might be our industry name
                        hierarchy['Sub_Category'] = title_text
                        if debug:
                            print(f"Found potential sub-category from title: {title_text}")
            
            # Method 3: Enhanced link-based extraction
            if breadcrumb_container:
                links = breadcrumb_container.find_all('a')
                text_items = []
                
                for link in links:
                    text = link.get_text(strip=True)
                    if text and text.lower() not in ['home', 'login', 'screens', 'dashboard', '']:
                        text_items.append(text)
                
                # Also look for non-link text in breadcrumbs
                all_text = breadcrumb_container.get_text(separator=' > ', strip=True)
                if '>' in all_text:
                    text_parts = [part.strip() for part in all_text.split('>')]
                    text_parts = [part for part in text_parts if part and part.lower() not in ['home', 'login', 'screens', 'dashboard']]
                    if len(text_parts) > len(text_items):
                        text_items = text_parts
                
                if debug:
                    print(f"Extracted breadcrumb items: {text_items}")
                
                # Find Industries and map hierarchy
                industries_index = -1
                for i, item in enumerate(text_items):
                    if item.lower() == 'industries':
                        industries_index = i
                        break
                
                if industries_index >= 0:
                    remaining = text_items[industries_index + 1:]
                    if len(remaining) >= 1:
                        hierarchy['Driving_Category'] = remaining[0]
                    if len(remaining) >= 2:
                        hierarchy['Category'] = remaining[1]
                    if len(remaining) >= 3:
                        hierarchy['Sector'] = remaining[2]
                    if len(remaining) >= 4:
                        hierarchy['Sub_Category'] = remaining[3]
            
            # Method 4: URL-based extraction as fallback
            if not any(hierarchy.values()[1:]):
                current_url = soup.find('meta', property='og:url')
                if current_url:
                    url = current_url.get('content', '')
                elif hasattr(soup, 'url'):
                    url = soup.url
                else:
                    url = ''
                
                if '/market/' in url:
                    # Extract from URL path
                    path_parts = url.split('/market/')[-1].split('/')
                    path_parts = [part for part in path_parts if part and part != '']
                    
                    # Map URL segments to hierarchy (this is speculative)
                    if len(path_parts) >= 1:
                        hierarchy['Sub_Category'] = path_parts[-1].replace('-', ' ').title()
            
            if debug:
                print(f"Final extracted hierarchy: {hierarchy}")
            
        except Exception as e:
            if debug:
                print(f"Error extracting hierarchy: {str(e)}")
        
        return hierarchy
    
    def extract_company_data(self, soup, industry_name, hierarchy, debug=False):
        """
        Enhanced company data extraction with aggressive numeric conversion
        """
        companies_data = []
        
        if debug:
            print("\nðŸ” DEBUG: Starting company data extraction...")
        
        try:
            # Look for data tables with various selectors
            table_selectors = [
                'table',
                '.data-table',
                '.table',
                '.companies-table',
                '.responsive-holder table',
                '[role="table"]'
            ]
            
            table = None
            for selector in table_selectors:
                tables = soup.select(selector)
                for t in tables:
                    # Check if this table contains company data
                    table_text = t.get_text().lower()
                    if any(indicator in table_text for indicator in ['company', 'cmp', 'market cap', 'sales', 'profit']):
                        table = t
                        if debug:
                            print(f"Found data table using selector: {selector}")
                        break
                if table:
                    break
            
            if not table:
                if debug:
                    print("No suitable data table found")
                return companies_data
            
            # Extract headers
            headers = []
            
            # Try multiple methods to find headers
            header_sources = [
                table.select('thead tr th'),
                table.select('thead tr td'),
                table.select('tr:first-child th'),
                table.select('tr:first-child td'),
            ]
            
            for header_source in header_sources:
                if header_source:
                    headers = [th.get_text(strip=True) for th in header_source]
                    headers = [h for h in headers if h]  # Remove empty headers
                    if headers:
                        break
            
            if debug:
                print(f"Found headers: {headers}")
            
            if not headers:
                if debug:
                    print("No headers found")
                return companies_data
            
            # Identify which columns should remain as text (only company names and similar)
            text_only_columns = set()
            for i, header in enumerate(headers):
                header_lower = header.lower()
                if any(keyword in header_lower for keyword in ['name', 'company', 'symbol', 'ticker']):
                    text_only_columns.add(i)
                    if debug:
                        print(f"Column {i} ('{header}') marked as text-only")
            
            # Extract data rows
            tbody = table.find('tbody')
            if not tbody:
                tbody = table
            
            rows = tbody.find_all('tr')
            
            # Skip header row if it's included in tbody
            start_index = 0
            if rows and len(rows) > 0:
                first_row_cells = [cell.get_text(strip=True) for cell in rows[0].find_all(['td', 'th'])]
                # If first row matches headers exactly, skip it
                if first_row_cells == headers:
                    start_index = 1
            
            for i, row in enumerate(rows[start_index:], start=1):
                cells = row.find_all(['td', 'th'])
                if len(cells) == 0:
                    continue
                
                # Create base row data with hierarchy info
                row_data = {
                    'Industry_Name': industry_name,
                    'Industry': hierarchy['Industry'],
                    'Driving_Category': hierarchy['Driving_Category'],
                    'Category': hierarchy['Category'],
                    'Sector': hierarchy['Sector'],
                    'Sub_Category': hierarchy['Sub_Category']
                }
                
                # Extract cell data with aggressive numeric conversion
                for j, cell in enumerate(cells):
                    if j < len(headers):
                        header = headers[j]
                        cell_text = cell.get_text(strip=True)
                        
                        # Clean header names for column naming
                        clean_header = (header.replace('.', '')
                                             .replace('Rs.', 'Rs')
                                             .replace('Rs.Cr.', 'Rs_Cr')
                                             .replace('%', 'Percent')
                                             .replace(' ', '_')
                                             .replace('/', '_')
                                             .replace('(', '')
                                             .replace(')', ''))
                        
                        # Convert to appropriate data type
                        if j in text_only_columns:
                            # Keep as text for company names/symbols
                            row_data[clean_header] = cell_text
                        else:
                            # Try to convert everything else to numbers
                            converted_value = self.convert_to_number(cell_text, debug=debug and i <= 3)
                            row_data[clean_header] = converted_value
                
                # Only add row if it has meaningful data
                non_hierarchy_data = {k: v for k, v in row_data.items() 
                                     if k not in ['Industry_Name', 'Industry', 'Driving_Category', 
                                                 'Category', 'Sector', 'Sub_Category']}
                
                if any(v for v in non_hierarchy_data.values()):
                    companies_data.append(row_data)
                    
                    if debug and i <= 3:
                        print(f"Sample row {i}: {dict(list(non_hierarchy_data.items())[:3])}")
            
            if debug:
                print(f"Extracted {len(companies_data)} companies")
                
        except Exception as e:
            if debug:
                print(f"Error extracting company data: {str(e)}")
            else:
                print(f"Error extracting company data: {str(e)}")
        
        return companies_data
    
    def get_industry_links(self):
        """
        Get all industry links from the market page
        """
        market_url = f"{self.base_url}/market/"
        
        try:
            print("ðŸ” Fetching industry list from market page...")
            response = self.session.get(market_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Find all industry links
            industry_links = soup.find_all('a', href=re.compile(r'/market/'))
            
            industries = []
            seen_names = set()
            
            for link in industry_links:
                href = link.get('href')
                industry_name = link.get_text(strip=True)
                
                # Skip invalid links
                if not href or not industry_name:
                    continue
                
                # Skip sorting/query parameters
                if '?' in href:
                    continue
                
                # Skip short names or duplicates
                if len(industry_name) < 2 or industry_name in seen_names:
                    continue
                
                # Skip generic links
                if industry_name.lower() in ['market', 'industries', 'home', 'login']:
                    continue
                
                # Validate URL structure
                path_segments = href.strip('/').split('/')
                if len(path_segments) < 2:
                    continue
                
                full_url = urljoin(self.base_url, href)
                
                industries.append({
                    'name': industry_name,
                    'url': full_url,
                    'href': href
                })
                
                seen_names.add(industry_name)
            
            print(f"   Found {len(industries)} valid industry links")
            return industries
            
        except Exception as e:
            print(f"âŒ Error fetching industry links: {str(e)}")
            return []
    
    def test_single_industry(self, debug=True):
        """
        Test extraction on a single industry
        """
        industries = self.get_industry_links()
        
        if not industries:
            print("âŒ No industries found to test")
            return None
        
        # Use first industry for testing
        test_industry = industries[0]
        
        print(f"\nðŸ§ª Testing with: {test_industry['name']}")
        print(f"   URL: {test_industry['url']}")
        
        try:
            response = self.session.get(test_industry['url'], timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extract hierarchy
            hierarchy = self.extract_breadcrumb_hierarchy(soup, debug=debug)
            
            # Extract company data
            companies_data = self.extract_company_data(soup, test_industry['name'], hierarchy, debug=debug)
            
            return {
                'industry': test_industry,
                'hierarchy': hierarchy,
                'companies_data': companies_data
            }
            
        except Exception as e:
            print(f"âŒ Error testing industry: {str(e)}")
            return None
    
    def scrape_all_industries(self, excel_filename):
        """
        Scrape all industries and their company data
        """
        print("\n" + "="*70)
        print("ðŸš€ STARTING FULL INDUSTRY & COMPANY DATA SCRAPING")
        print("="*70)
        
        # Ensure we're logged in
        if not self.logged_in:
            print("âš ï¸ Not logged in, attempting login first...")
            if not self.login():
                print("âŒ Login failed, proceeding without authentication...")
        
        industries = self.get_industry_links()
        
        if not industries:
            print("âŒ No industries found!")
            return None
        
        all_company_data = []
        processed_count = 0
        total_companies = 0
        failed_industries = []
        
        print(f"ðŸ“Š Processing {len(industries)} industries...")
        
        for industry in industries:
            processed_count += 1
            
            try:
                print(f"\n[{processed_count}/{len(industries)}] Processing: {industry['name']}")
                print(f"    URL: {industry['url']}")
                
                response = self.session.get(industry['url'], timeout=30)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Extract hierarchy
                hierarchy = self.extract_breadcrumb_hierarchy(soup, debug=False)
                hierarchy_display = " > ".join([h for h in [
                    hierarchy['Driving_Category'], 
                    hierarchy['Category'], 
                    hierarchy['Sector'], 
                    hierarchy['Sub_Category']
                ] if h])
                
                print(f"    ðŸ“‚ Hierarchy: {hierarchy_display}")
                
                # Extract company data
                companies_data = self.extract_company_data(soup, industry['name'], hierarchy, debug=False)
                
                if companies_data:
                    all_company_data.extend(companies_data)
                    total_companies += len(companies_data)
                    print(f"    âœ… Found {len(companies_data)} companies (Total: {total_companies})")
                else:
                    print(f"    âš ï¸ No companies found")
                    failed_industries.append(industry['name'])
                
                # Be respectful to the server
                time.sleep(2)
                
            except Exception as e:
                print(f"    âŒ Error processing {industry['name']}: {str(e)}")
                failed_industries.append(industry['name'])
                continue
        
        # Create and save DataFrame
        if all_company_data:
            print(f"\nðŸŽ‰ DATA EXTRACTION COMPLETED!")
            print(f"   ðŸ“Š Industries processed: {processed_count}")
            print(f"   ðŸ¢ Total companies: {len(all_company_data)}")
            print(f"   âŒ Failed industries: {len(failed_industries)}")
            
            if failed_industries:
                print(f"   Failed: {', '.join(failed_industries[:5])}" + 
                      (f" and {len(failed_industries)-5} more..." if len(failed_industries) > 5 else ""))
            
            return self.save_to_excel(all_company_data, excel_filename)
        else:
            print("âŒ No data extracted!")
            return None
    
    def save_to_excel(self, companies_data, filename):
        """
        Save data to Excel with proper formatting and data types
        """
        try:
            df = pd.DataFrame(companies_data)
            
            # Add global serial number
            df['Global_S_No'] = range(1, len(df) + 1)
            
            # Force numeric conversion for all non-text columns
            identifier_columns = ['Global_S_No', 'Industry_Name', 'Industry', 
                                'Driving_Category', 'Category', 'Sector', 'Sub_Category']
            
            # Convert all remaining columns to proper numeric types
            for col in df.columns:
                if col not in identifier_columns:
                    # Check if column has string values that look like company names
                    sample_values = df[col].dropna().head(10)
                    
                    # If most values are clearly company names, keep as text
                    if len(sample_values) > 0:
                        text_count = sum(1 for val in sample_values 
                                       if isinstance(val, str) and len(str(val)) > 10 and 
                                       any(word in str(val).lower() for word in ['ltd', 'limited', 'inc', 'corp', 'pvt']))
                        
                        # If more than 50% look like company names, keep as text
                        if text_count / len(sample_values) > 0.5:
                            continue
                    
                    # Otherwise, ensure all values are numeric
                    df[col] = df[col].apply(lambda x: self.convert_to_number(x) if pd.notna(x) else 0.0)
            
            # Reorder columns
            other_columns = [col for col in df.columns if col not in identifier_columns]
            final_columns = identifier_columns + other_columns
            final_columns = [col for col in final_columns if col in df.columns]
            df = df[final_columns]
            
            print(f"\nðŸ’¾ Saving data to: {filename}")
            
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # Main data sheet
                df.to_excel(writer, sheet_name='All_Companies_Data', index=False)
                
                # Summary sheet
                summary_df = df.groupby(['Industry_Name', 'Driving_Category', 'Category', 
                                       'Sector', 'Sub_Category']).size().reset_index(name='Company_Count')
                summary_df['Summary_S_No'] = range(1, len(summary_df) + 1)
                summary_df = summary_df[['Summary_S_No'] + [col for col in summary_df.columns if col != 'Summary_S_No']]
                summary_df.to_excel(writer, sheet_name='Industry_Summary', index=False)
                
                # Data types sheet for reference
                dtypes_data = []
                for col in df.columns:
                    sample_values = df[col].dropna().head(5).tolist()
                    numeric_count = sum(1 for val in df[col].dropna() if isinstance(val, (int, float)))
                    text_count = sum(1 for val in df[col].dropna() if isinstance(val, str))
                    
                    dtypes_data.append({
                        'Column_Name': col,
                        'Data_Type': str(df[col].dtype),
                        'Non_Null_Count': df[col].count(),
                        'Numeric_Values': numeric_count,
                        'Text_Values': text_count,
                        'Sample_Values': str(sample_values)
                    })
                
                dtypes_df = pd.DataFrame(dtypes_data)
                dtypes_df.to_excel(writer, sheet_name='Data_Types_Info', index=False)
                
                # Format the sheets
                self._format_excel_sheets(writer, df, summary_df)
            
            print(f"âœ… SUCCESS! Data saved to {filename}")
            print(f"ðŸ“Š Total companies: {len(df)}")
            print(f"ðŸ“‚ Industries: {len(summary_df)}")
            
            # Display data type summary
            print(f"\nðŸ“‹ DATA TYPES SUMMARY:")
            numeric_cols = 0
            text_cols = 0
            for col in df.columns:
                if col not in identifier_columns:
                    if pd.api.types.is_numeric_dtype(df[col]):
                        numeric_cols += 1
                    else:
                        text_cols += 1
            
            print(f"   ðŸ”¢ Numeric columns: {numeric_cols}")
            print(f"   ðŸ“ Text columns: {text_cols}")
            print(f"   ðŸ“‹ Total data columns: {len(df.columns) - len(identifier_columns)}")
            
            # Show conversion summary
            print(f"\nðŸ”„ CONVERSION SUMMARY:")
            for col in df.columns:
                if col not in identifier_columns:
                    non_null_values = df[col].dropna()
                    if len(non_null_values) > 0:
                        numeric_count = sum(1 for val in non_null_values if isinstance(val, (int, float)))
                        text_count = sum(1 for val in non_null_values if isinstance(val, str))
                        conversion_rate = (numeric_count / len(non_null_values)) * 100
                        
                        if conversion_rate > 90:
                            print(f"   âœ… {col}: {conversion_rate:.1f}% numeric ({numeric_count}/{len(non_null_values)})")
                        elif conversion_rate > 50:
                            print(f"   âš ï¸ {col}: {conversion_rate:.1f}% numeric ({numeric_count}/{len(non_null_values)})")
                        else:
                            print(f"   ðŸ“ {col}: {conversion_rate:.1f}% numeric ({numeric_count}/{len(non_null_values)}) - Text column")
            
            return df
            
        except Exception as e:
            print(f"âŒ Error saving Excel file: {str(e)}")
            return None
    
    def _format_excel_sheets(self, writer, df, summary_df):
        """
        Apply formatting to Excel sheets
        """
        try:
            from openpyxl.styles import Font, PatternFill, Alignment
            from openpyxl.utils import get_column_letter
            from openpyxl.styles.numbers import FORMAT_NUMBER_COMMA_SEPARATED1, FORMAT_PERCENTAGE_00
            
            # Format main sheet
            if 'All_Companies_Data' in writer.sheets:
                ws = writer.sheets['All_Companies_Data']
                
                # Header formatting
                header_font = Font(bold=True, color='FFFFFF')
                header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')
                
                for cell in ws[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Apply number formatting to numeric columns
                for col_idx, col_name in enumerate(df.columns, 1):
                    col_letter = get_column_letter(col_idx)
                    
                    if pd.api.types.is_numeric_dtype(df[col_name]):
                        # Check if it's likely a percentage column
                        if 'percent' in col_name.lower() or '%' in col_name:
                            # Format as percentage
                            for row in range(2, ws.max_row + 1):
                                cell = ws[f'{col_letter}{row}']
                                if cell.value is not None and isinstance(cell.value, (int, float)):
                                    cell.number_format = FORMAT_PERCENTAGE_00
                        else:
                            # Format as number with commas for large numbers
                            for row in range(2, ws.max_row + 1):
                                cell = ws[f'{col_letter}{row}']
                                if cell.value is not None and isinstance(cell.value, (int, float)):
                                    if abs(cell.value) >= 1000:
                                        cell.number_format = FORMAT_NUMBER_COMMA_SEPARATED1
                                    else:
                                        cell.number_format = '0.00'
                
                # Column widths
                column_widths = {
                    'A': 12, 'B': 35, 'C': 12, 'D': 25, 'E': 35, 'F': 20, 'G': 20
                }
                
                for col_letter, width in column_widths.items():
                    ws.column_dimensions[col_letter].width = width
                
                # Auto-width for other columns
                for i in range(8, min(len(df.columns) + 1, 30)):
                    ws.column_dimensions[get_column_letter(i)].width = 15
            
            # Format summary sheet
            if 'Industry_Summary' in writer.sheets:
                ws = writer.sheets['Industry_Summary']
                
                for cell in ws[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = Alignment(horizontal='center', vertical='center')
                
                summary_widths = {'A': 12, 'B': 35, 'C': 25, 'D': 35, 'E': 20, 'F': 20, 'G': 15}
                for col_letter, width in summary_widths.items():
                    ws.column_dimensions[col_letter].width = width
            
            # Format data types sheet
            if 'Data_Types_Info' in writer.sheets:
                ws = writer.sheets['Data_Types_Info']
                
                for cell in ws[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = Alignment(horizontal='center', vertical='center')
                
                ws.column_dimensions['A'].width = 25  # Column_Name
                ws.column_dimensions['B'].width = 15  # Data_Type
                ws.column_dimensions['C'].width = 15  # Non_Null_Count
                ws.column_dimensions['D'].width = 15  # Numeric_Values
                ws.column_dimensions['E'].width = 15  # Text_Values
                ws.column_dimensions['F'].width = 50  # Sample_Values
                    
        except Exception as e:
            print(f"âš ï¸ Warning: Could not apply Excel formatting: {str(e)}")

def validate_extraction():
    """
    Test and validate the extraction process with enhanced numeric conversion
    """
    scraper = ScreenerScraper()
    
    while True:
        print("\n" + "="*70)
        print("ðŸ§ª TESTING ENHANCED SCRAPER WITH AGGRESSIVE NUMERIC CONVERSION")
        print("="*70)
        
        # Login first
        if not scraper.login():
            print("âŒ Login failed. Continue anyway? (y/n): ", end="")
            if input().strip().lower() != 'y':
                return False
        
        # Test numeric conversion function first
        print("\nðŸ”¢ TESTING NUMERIC CONVERSION:")
        test_values = [
            "1,23,456",           # Indian number format
            "12.5Cr",             # Crores
            "5.2L",               # Lakhs
            "15.67%",             # Percentage
            "(25.3)",             # Negative in parentheses
            "-45.2",              # Regular negative
            "Rs. 1,500",          # Currency
            "â‚¹2,50,000",          # Indian currency
            "N/A",                # Not applicable -> should be 0
            "Reliance Industries Ltd", # Company name (should stay text)
            "123.45",             # Regular decimal
            "0.0067%",            # Small percentage
            "456.78K",            # Thousands
            "2.5M",               # Millions
            "abc",                # Pure text -> should be 0 or stay text
            "12,34,56,789",       # Large Indian number
            "--",                 # Empty indicator -> should be 0
        ]
        
        for test_val in test_values:
            converted = scraper.convert_to_number(test_val, debug=False)
            val_type = type(converted).__name__
            print(f"   '{test_val}' -> {converted} ({val_type})")
        
        print("\n" + "-"*50)
        
        # Test extraction
        test_result = scraper.test_single_industry(debug=True)
        
        if not test_result:
            print("âŒ Test failed!")
            return False
        
        industry = test_result['industry']
        hierarchy = test_result['hierarchy']
        companies_data = test_result['companies_data']
        
        # Display results
        print(f"\nðŸ“‹ RESULTS for '{industry['name']}':")
        print("-" * 50)
        print(f"ðŸ—ï¸ HIERARCHY:")
        for key, value in hierarchy.items():
            print(f"   {key}: {value if value else '(Not found)'}")
        
        print(f"\nðŸ“Š COMPANY DATA:")
        print(f"   Total companies: {len(companies_data)}")
        
        if companies_data:
            df_sample = pd.DataFrame(companies_data)
            print(f"   Columns found: {list(df_sample.columns)}")
            
            # Show data types and conversion rates
            print(f"\nðŸ”¢ DATA CONVERSION ANALYSIS:")
            identifier_cols = ['Industry_Name', 'Industry', 'Driving_Category', 
                             'Category', 'Sector', 'Sub_Category']
            
            numeric_cols = []
            text_cols = []
            mixed_cols = []
            
            for col in df_sample.columns:
                if col not in identifier_cols:
                    non_null_values = df_sample[col].dropna()
                    if len(non_null_values) > 0:
                        numeric_count = sum(1 for val in non_null_values if isinstance(val, (int, float)))
                        text_count = sum(1 for val in non_null_values if isinstance(val, str))
                        conversion_rate = (numeric_count / len(non_null_values)) * 100
                        
                        if conversion_rate >= 95:
                            numeric_cols.append(f"{col} ({conversion_rate:.0f}%)")
                        elif conversion_rate <= 20:
                            text_cols.append(f"{col} ({conversion_rate:.0f}%)")
                        else:
                            mixed_cols.append(f"{col} ({conversion_rate:.0f}%)")
            
            print(f"   âœ… Fully numeric columns ({len(numeric_cols)}): {numeric_cols}")
            print(f"   ðŸ“ Text columns ({len(text_cols)}): {text_cols}")
            if mixed_cols:
                print(f"   âš ï¸ Mixed columns ({len(mixed_cols)}): {mixed_cols}")
            
            print(f"\nðŸ” SAMPLE COMPANIES (first 3):")
            for i, row in df_sample.head(3).iterrows():
                print(f"\n   Company {i+1}:")
                sample_data = {}
                for col, val in row.items():
                    if col not in identifier_cols:
                        sample_data[col] = val
                        if len(sample_data) >= 6:  # Show first 6 non-identifier columns
                            break
                
                for col, val in sample_data.items():
                    val_type = type(val).__name__
                    if isinstance(val, float):
                        print(f"     {col}: {val:.2f} ({val_type})")
                    else:
                        print(f"     {col}: {val} ({val_type})")
        
        # Validation
        print("\n" + "="*70)
        print("ðŸ“Š NUMERIC CONVERSION SUMMARY:")
        print(f"   â€¢ All financial data should be numeric (int/float)")
        print(f"   â€¢ Only company names and categories should remain as text")
        print(f"   â€¢ Empty/null values should convert to 0.0")
        print(f"   â€¢ Percentages should remain as numbers (not converted to decimals)")
        
        while True:
            response = input("\nâœ… Is the numeric conversion working correctly? (yes/no/quit): ").strip().lower()
            
            if response in ['yes', 'y']:
                return True
            elif response in ['no', 'n']:
                print("ðŸ”„ Trying again...")
                break
            elif response in ['quit', 'q', 'exit']:
                return False
            else:
                print("Please enter 'yes', 'no', or 'quit'")

def main():
    """
    Main function to run the enhanced scraper with aggressive numeric conversion
    """
    print("ðŸš€ Enhanced Screener.in Scraper - AGGRESSIVE NUMERIC CONVERSION")
    print("="*70)
    print("ðŸŽ¯ Goal: Convert ALL data to numbers except company names and categories")
    print("="*70)
    
    # Validate extraction
    if not validate_extraction():
        print("âŒ Validation failed. Exiting.")
        return
    
    # Get filename
    while True:
        filename = input("\nðŸ“ Enter Excel filename (e.g., 'screener_data.xlsx'): ").strip()
        
        if not filename:
            print("Please enter a valid filename.")
            continue
        
        if not filename.lower().endswith('.xlsx'):
            filename += '.xlsx'
        
        print(f"âœ… Will save to: {filename}")
        break
    
    # Start full scraping
    scraper = ScreenerScraper()
    
    print(f"\nðŸš€ Starting full extraction with aggressive numeric conversion...")
    df = scraper.scrape_all_industries(filename)
    
    if df is not None:
        print(f"\nðŸŽ‰ SCRAPING COMPLETED SUCCESSFULLY!")
        print(f"ðŸ“Š Final dataset contains {len(df)} companies")
        
        # Validate final numeric conversion
        print(f"\nðŸ” FINAL NUMERIC CONVERSION VALIDATION:")
        identifier_cols = ['Global_S_No', 'Industry_Name', 'Industry', 'Driving_Category', 
                          'Category', 'Sector', 'Sub_Category']
        
        data_columns = [col for col in df.columns if col not in identifier_cols]
        total_numeric = 0
        total_text = 0
        
        for col in data_columns:
            non_null_values = df[col].dropna()
            if len(non_null_values) > 0:
                numeric_count = sum(1 for val in non_null_values if isinstance(val, (int, float)))
                text_count = sum(1 for val in non_null_values if isinstance(val, str))
                
                if numeric_count > text_count:
                    total_numeric += 1
                else:
                    total_text += 1
        
        print(f"   ðŸ”¢ Columns with mostly numeric data: {total_numeric}")
        print(f"   ðŸ“ Columns with mostly text data: {total_text}")
        print(f"   ðŸ“Š Numeric conversion rate: {(total_numeric/(total_numeric+total_text)*100):.1f}%")
        
        # Show sample of converted data
        print(f"\nðŸ” Sample of final converted data:")
        sample_df = df.head(2)
        
        for idx, row in sample_df.iterrows():
            company_name = "Unknown"
            for col in row.index:
                if 'name' in col.lower() and isinstance(row[col], str) and len(str(row[col])) > 5:
                    company_name = str(row[col])[:30]
                    break
            
            print(f"\n{int(row['Global_S_No'])}. {company_name}")
            print(f"   Industry: {row['Industry_Name']}")
            
            # Show numeric data samples
            numeric_data = {}
            for col in data_columns[:8]:  # Show first 8 data columns
                if col in row.index and pd.notna(row[col]):
                    val = row[col]
                    if isinstance(val, (int, float)):
                        numeric_data[col] = f"{val} ({type(val).__name__})"
                    else:
                        numeric_data[col] = f"{val} (text)"
            
            for col, val_info in numeric_data.items():
                print(f"   {col}: {val_info}")
        
        print(f"\nðŸ“‹ Data saved to {filename} with aggressive numeric conversion!")
        print(f"ðŸŽ¯ Mission: Convert all financial data to numbers - COMPLETED!")
    else:
        print(f"\nâŒ Scraping failed.")

if __name__ == "__main__":
    main()
